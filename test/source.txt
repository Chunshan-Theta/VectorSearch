標題:為什麼臺灣一定要發展大型語言模型？專訪「生成式 AI 對話引擎 TAIDE 」核心模型訓練與 RLHF 小組召集人蔡宗翰教授
出版時間:112/12/27
瀏覽次數:18
作者:廖珮君, 科技大觀園特約編輯


ChatGPT 帶動生成式 AI 應用浪潮，許多國家及科技巨頭紛紛投注資源發展大型語言模型，我國也在 2023 年初號召各界共同打造可信任生成式 AI 對話引擎（ TAIDE, Trustworthy AI Dialogue Engine），並在眾人努力下持續尋求技術層面的突破。數位發展部部長唐鳳日前出席「2023 Trustworthy AI 國際研討會」時更表示，自己已經在使用 TAIDE 最新測試版撰寫中文郵件，並肯定從 TAIDE 從第一版至今進步非常顯著。
TAIDE 架構在國家高速網路與計算中心的超級電腦「臺灣杉 2 號」上，並使用繁體中文作為訓練語料，融入臺灣特有的語言、價值觀、風俗習慣等元素，讓 TAIDE 更能理解與回應本土使用者的需求。擔任 TAIDE 對話引擎核心模型訓練與 RLHF 小組召集人 （ RLHF 意即「基於人類反饋的強化學習」，英文全稱為 Reinforcement Learning from Human Feedback）的中央研究院人文社會科學研究中心研究員暨國立中央大學資訊工程學系教授蔡宗翰分享，雖然 TAIDE 的開發已持續一段時間，但仍有不少人好奇為何臺灣一定要打造專屬對話引擎，不能直接使用現成的大型語言模型即可？

臺灣必須發展 TAIDE 對話引擎的 2 個原因，蔡宗翰認為，避免 AI 人才斷層風險、掌控 AI 服務存取權，是臺灣一定要發展 TAIDE 的 2 個原因。以汽車產業為例，臺灣在 1970 年代汽車產業起飛時，因為沒有訓練汽車引擎的製造工藝，導致如今只能搶攻元件供應及後端組裝兩塊市場。大型語言模型的概念亦是如此，正因未來生成式 AI 對話引擎的應用是必然趨勢，所以臺灣如果現在不加緊投入發展大語言模型，未來在世界就會失去話語權，同時面臨 AI 人才斷層的風險。
「AI 服務受制於人，指的就是 AI 服務存取權受到他人控制，」蔡宗翰強調，如果臺灣沒有發展自有大型語言模型，就只能使用其他國家或企業發展的對話引擎。然而這麼一來不僅會無法掌控 AI 生成內容的品質，在遇到負載過高、網路塞車的時候，對方也可能會調低臺灣用戶的服務優先權，形同 AI 服務存取權限受到他人控制。

以 LLaMA 2 大型語言模型為基礎進行調校，大型語言模型如果從零開始建立，訓練語料至少需要 1 兆個字、500-1000 萬美金的成本及 6 個月時間，這對資源有限的臺灣來說並不容易。因此 TAIDE 以現有的大型語言模型 LLaMA 2（在 2023 年 7 月由 Meta 推出的大型語言模型）為基礎，進行中文的訓練調校，如此一來不只可以節省時間和金錢成本，訓練語料量也減少至 10 億個字，成為臺灣發展 TAIDE 的最佳策略。
另一方面，考量到 TAIDE 是以服務公部門、成為政府的數位大腦為主要目標，因此在訓練語料的選擇上，便以內容供應者提供的第一手資料為主，例如政府資料、雜誌文章與書籍等，而不是經由網路搜尋來的二手資料。以第一手資料作為訓練語料的優點，在於可以避免著作權及資料正確性的爭議，同時省下清洗資料的時間。
蔡宗翰分析，在每 100GB 的網路資料中， 可能包含 2 千萬個不同網站，但每一個網站都有很多無用或重複資料，光是清理資料就必須耗費許多時間和資源，因此如果能在一開始就以流暢、具邏輯且有組織的乾淨資料訓練大型語言模型，就能避免不必要的資源浪費，並確保大型語言模型的對話能力與內容品質。

TAIDE 的應用與展望，目前 TAIDE 已開發至第 11 版，能力等同 GPT-3.5，可以撰寫電子郵件、文章、公文與進行中英翻譯、自動摘要等工作，並在開放測試帳號申請後，已有許多公部門及企業表達導入意願，能提升更多臺灣工作者文書處理的效率。接下來， TAIDE 還將會朝向中高階模型邁進，讓這個大型語言模型不只是處理文書行政作業的幫手，更能成為政府人員的幕僚，協助發想更多有利於社會的政策，並開啟更多應用可能。
蔡宗翰提到，在開發 TAIDE 之後，不僅能減少 AI 人才斷層與 AI 服務存取權受到他人控制的風險，未來也希望能將臺灣發展 TAIDE 的經驗分享給其他國家，運用科技外交提高臺灣的國際知名度。

